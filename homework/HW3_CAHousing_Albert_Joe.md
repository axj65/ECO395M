## 4. Predictive Model Building: California Housing

### Methods

On this exercise, I generated 4 models: a KNN Model, a Random Forest
Model, a GBM model, and a Stacked Model. I partitioned the dataset into
a training set and a test set using an 80-20 split. For all models, the
training set is used for training the model, hyperparameter tuning, and
model selection. All K-fold cross validation was done on the training
set; the test set was reserved for final validation of the models.

#### KNN Model

The KNN Model was used as an initial Benchmark. The following show the
RMSEs. The in-sample RMSE was generated using an average of 5
cross-validated RMSEs. The out-of-sample RMSE show the RMSE of
predictions on the test set.

    ## KNN in-sample RMSE: 64426.16

    ## KNN out-of-sample RMSE: 61816.65

#### Random Forest Model

The following show the RMSE results for the Random Forest Model. These
show that there was significant improvement from the KNN Model, and
serves as another benchmark to compare the GBM model to.

    ## Random Forest Model in-sample RMSE: 22931.11

    ## Random Forest Model out-of-sample RMSE: 53022.07

#### GBM Model

The GBM Model was trained using 5 cross validated folds with an
interaction depth of 10, a shrinkage of 0.1, and 1,000 trees. This model
outperformed the Random Forest Model over 5 random seeds. The following
show the RMSEs of the GBM Model.

    ## GBM in-sample RMSE: 30756.46

    ## GBM out-of-sample RMSE: 46843.96

#### Stacked Model

Finally, I used a Stacked Model, in which I used an ensemble approach
combining the predictions of the three separate GBM Models and used
another GBM Model as a second level learner to stack the individual
model predictions. Each GBM Model was generated by using a different
random seed. Although the improvement on this model was relatively
minor, this model outperformed the normal GBM Model over 5 random seeds.
Consequently, this is my model of choice for generating the best
predictive model. The following show the RMSEs of this model.

    ## Stacked Model in-sample RMSE: 29058.24

    ## Stacked Model out-of-sample RMSE: 46224.05

#### Cross-Validated Predictions using the Stacked Model

Because I want to plot my predictions and residuals versus the
geolocation, I generated cross-validated predictions using my stacked
model. I first created 5 folds, using 4 folds as the training set and 1
fold as the test set. Using the training set, I created 3 separate GBM
Models and passed them through a second-level learner (also using GBM)
to generate predictions for the test set. I did this until each fold was
used as a test set once so that out-of-sample predictions was generated
for the whole dataset.

The following shows the average RMSE of my predictions versus the actual
medianHouseValues. This is the overall out-of-sample accuracy of my
proposed model.

    ## Stacked Model out-of-sample RMSE: 45850.39
