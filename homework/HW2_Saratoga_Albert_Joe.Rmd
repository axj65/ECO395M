---
title: "HW2: Saratoga House Prices"
output: "md_document"
date: "2023-02-22"
---

```{r, include=FALSE}

#Set Directory
knitr::opts_chunk$set(echo = FALSE, include = TRUE)
knitr::opts_knit$set(root.dir = "/Users/albertjoe33/Documents/UT_Austin/Stat_Learning/ECO395M/homework/")

#Load Libraries
library(readr)
library(tidyverse)
library(rsample)
library(caret)
library(modelr)
library(parallel)
library(foreach)
library(dplyr)
library(rmarkdown)
#library(lubridate)
library(mosaic)
library(caret)

#Load Datasets
data("SaratogaHouses")
german_credit <- read_csv("Data/german_credit.csv")
hotels_dev <- read_csv("Data/hotels_dev.csv")
hotels_val <- read_csv("Data/hotels_val.csv")

```


## 1. Saratoga House Prices

<br/>

### a. Linear Model to Predict Price
<br/>

The goal of this exercise is to build a linear model with the lowest RMSE. The first thing to do is to explore the data in order to guide the initial selection of variables for the model. You can find these plots in Appendix 1. I will show three models in this exercise. The first is the model from class, used as a reference. The second is a model with hand-selected variables. The third is a stepwise regression model with all the varialbes included in the second model and their two-way interactions. 

<br/>
```{r chunk1}

#Histograms

saratoga_hist <- SaratogaHouses[c("price", "age", "livingArea", "pctCollege", "lotSize", "landValue")]

saratoga_hist <- saratoga_hist %>% mutate(price = price/1000)
saratoga_hist <- saratoga_hist %>% mutate(landValue = landValue/1000)


hist_plots <- saratoga_hist %>%
  gather(key = "var", value = "value") %>% 
  ggplot(aes(x = value)) +
    geom_histogram() +
    facet_wrap(~ var, scales = "free") +
    xlab("Note: Dollar Values are in Thousands") +
    ylab("Count")
```


```{r chunk2}

#scatterplots on continuous variables

saratoga_numeric <- SaratogaHouses[c("price", "lotSize", "age", "livingArea", "pctCollege", "landValue")]

saratoga_numeric <- saratoga_numeric %>% mutate(price = price/1000)
saratoga_numeric <- saratoga_numeric %>% mutate(landValue = landValue/1000)

scatter_plots <- saratoga_numeric %>%
  gather(-price, key = "var", value = "value") %>% 
  ggplot(aes(x = value, y = price)) +
    geom_point() +
    facet_wrap(~ var, scales = "free") +
    xlab("") +
    ylab("Price in Thousands of Dollars")

```


```{r chunk3, warning=FALSE}

#Boxplots on categorical variables

saratoga_box <- SaratogaHouses[c("price", "fireplaces", "heating", "fuel", "sewer", "waterfront", "centralAir")]

saratoga_box <- saratoga_box %>% mutate(price = price/1000)

box_plots <- saratoga_box %>%
  gather(-price, key = "var", value = "value") %>% 
  ggplot(aes(x = value, y = price)) +
    geom_boxplot() +
    facet_wrap(~ var, scales = "free") +
    theme(axis.text.x = element_text(angle = 45, hjust = .35, vjust = 0.5)) +
    xlab("") +
    ylab("Price in Thousands of Dollars")

```


```{r chunk4}

#Boxplots on categorical variables

saratoga_box2 <- SaratogaHouses[c("price", "bedrooms", "bathrooms", "rooms")]

saratoga_box2 <- saratoga_box2 %>% mutate(price = price/1000)

box_plots2 <- saratoga_box2 %>%
  gather(-price, key = "var", value = "value") %>% 
  ggplot(aes(x = factor(value), y = price)) +
    geom_boxplot() +
    facet_wrap(~ var, scales = "free") +
    theme(axis.text.x = element_text(angle = 45, hjust = .35, vjust = 0.5), aspect.ratio = 2/3) +
    xlab("") +
    ylab("Price in Thousands of Dollars")

```

<br/>

The first model is the medium model from class to use as a reference and consists of the following:

```{r chunk5}

#Medium Model from Class for comparison
lm_medium <- lm(price ~ lotSize + age + livingArea + bedrooms + fireplaces + bathrooms + rooms + heating + fuel + centralAir, data=SaratogaHouses)
getCall(lm_medium)
```

<br/>

The second model is a model of my creation using exploratory data analysis and tinkering with the formula. This model is also used as a starting point for the stepwise regrsesion in the third model. In this model, I did not include 'newConstruction' as it is captured in the 'age' variable. I also did not include 'sewer' as the boxplot showed no noticeable affect on price. The second model consists of the following: 

```{r chunk6}
#Make initial lm model
lm1 <- lm(price ~ lotSize + age + landValue + livingArea + pctCollege + bedrooms + fireplaces + bathrooms + rooms + heating + fuel + waterfront + centralAir, data=SaratogaHouses)

getCall(lm1)
```

<br/>

The third model runs stepwise regression with all the variables from the second model and their 2-way interactions. The result of the stepwise regression results in the following formula: 

```{r chunk7, include=FALSE}
stepWise <- step(lm1, scope=~(.)^2)
```

```{r chunk8}
getCall(stepWise)
```

<br/>

I now use K-fold cross validation (5 folds) to compare all the models. The following shows the average RMSE for the 3 models:

```{r chunk9}

set.rseed(1994)

#Compare models using K-fold cross validation
K_folds = 5

SaratogaHouses = SaratogaHouses %>%
  mutate(fold_id = rep(1:K_folds, length=nrow(SaratogaHouses)) %>% sample)

#RMSE of a Model of my creation without steps
rmse_lm1 = foreach(fold = 1:K_folds, .combine = 'c') %do% {
  lm1 <- lm(price ~ lotSize + age + landValue + livingArea + pctCollege + bedrooms + fireplaces + bathrooms + rooms + heating + fuel +                     waterfront + centralAir,
                    data=filter(SaratogaHouses, fold_id!=fold))
  modelr::rmse(lm1, data = filter(SaratogaHouses, fold_id == fold))
}

#RMSE of Medium Model
rmse_lm_medium = foreach(fold = 1:K_folds, .combine = 'c') %do% {
  lm_medium <- lm(price ~ . - pctCollege - sewer - waterfront - landValue - newConstruction, 
                  data=filter(SaratogaHouses, fold_id!=fold))
  modelr::rmse(lm_medium, data = filter(SaratogaHouses, fold_id == fold))
}

#RMSE of Stepwise Model
rmse_lm_step = foreach(fold = 1:K_folds, .combine = 'c') %do% {
  lm_step <- lm(formula = price ~ lotSize + age + landValue + livingArea + 
    pctCollege + bedrooms + fireplaces + bathrooms + rooms + 
    heating + fuel + waterfront + centralAir + livingArea:centralAir + 
    landValue:livingArea + age:landValue + livingArea:fuel + 
    bathrooms:heating + landValue:pctCollege + pctCollege:fireplaces + 
    livingArea:fireplaces + bedrooms:fireplaces + landValue:fireplaces + 
    landValue:bathrooms + fireplaces:waterfront + lotSize:waterfront + 
    fuel:centralAir + age:centralAir + age:pctCollege + lotSize:age + 
    livingArea:pctCollege + lotSize:landValue + landValue:fuel + 
    age:bathrooms + rooms:heating + bedrooms:heating, data=filter(SaratogaHouses, fold_id!=fold))
  modelr::rmse(lm_step, data = filter(SaratogaHouses, fold_id == fold))
}


cat("Model 1 (Medium Linear Model)- Mean RMSE:", mean(rmse_lm_medium),  "\n")
cat("Model 2 (Hand Selected Linear Model)- Mean RMSE:", mean(rmse_lm1), "\n")
cat("Model 3 (Stepwise Linear Model)- Mean RMSE:", mean(rmse_lm_step))


```

<br/>

### b. KNN Model to Predict Price

<br/>

In order to conduct KNN, I first used my exploratory data analysis plots to guide selection of initial variables. I then used Z-score scaling to scale all the parameters. Lastly, I added and removed variables to test which models returned the lowest RMSE. I also found that the optimal k value for KNN Regression in this model was k=9. 

<br/>

```{r chunk10}
#Scale the variables for KNN
SaratogaHouses_standardized <- scale(SaratogaHouses[,2:10])
SaratogaHouses_standardized <- cbind(SaratogaHouses$price, SaratogaHouses_standardized)
SaratogaHouses_standardized <- cbind(SaratogaHouses_standardized, SaratogaHouses[,11:17])
colnames(SaratogaHouses_standardized)[1] <- "price"
```

```{r chunk11}
#train-test split
saratoga_split = initial_split(SaratogaHouses_standardized, prop = 0.8)
saratoga_train = training(saratoga_split)
saratoga_test = testing(saratoga_split)

#find optimal number for k in KNN
df_saratoga <- data.frame(K = numeric(), K_RSME = numeric())

for (i in 2:25) {
  knn_saratoga = knnreg(price ~ livingArea + bedrooms + bathrooms + landValue + age + pctCollege + waterfront + lotSize, 
                        data = saratoga_train, k = i)
  k_rsme = rmse(knn_saratoga, saratoga_test)
  new_row <- data.frame(K = i, K_RSME = k_rsme)
  df_saratoga <- bind_rows(df_saratoga, new_row)
}

#Found k=9 is optimal k value

```


```{r chunk12}
#Medium RMSE
rmse_knn_saratoga = foreach(fold = 1:K_folds, .combine = 'c') %do% {
  knn_saratoga = knnreg(price ~ livingArea + bedrooms + bathrooms + landValue + age + pctCollege + waterfront + lotSize, 
                  data=filter(SaratogaHouses_standardized, fold_id!=fold), k=9)
  modelr::rmse(knn_saratoga, data = filter(SaratogaHouses_standardized, fold_id == fold))
}

cat("Using k=9 and K-fold cross validation with 5 folds, I got an average RMSE of:", mean(rmse_knn_saratoga))

```

<br/>

### c. Tax Authority Report

<br/>

Overall, the Stepwise Regression Model performed the best in terms of the root mean-squared error (RMSE) with an average RMSE of 57702.23. A hand-selected linear model without any interactions placed second with an average RMSE of 59378.08. The K-Nearest Neighbors (KNN) Regression performed the worst with an average RMSE of 60802.39. So what do these results mean for tax purposes?

<br/>

If the tax authority wants the most accurate prediction for property prices, the Stepwise Regression Model clearly outperforms the other models. However, this model is hardly interpretable due to the many interactions among the various attributes of the home. When homeowners protest the value of their home in order to lower property taxes, this model would be extremely difficult to explain to the court authorities determining whether to decrease the value of a home. Consequently, I recommend doing further analysis on and possibly using the hand-selected linear model. The difference between the average RMSE is only approximately 1700, whereas the decrease in property values after a homeowner protests have sometimes been greater than 50,000. I purposely hand-selected a model without transformations and interactions because this model is highly interpretable. In other words, the tax authority can point to specific aspects of the home and state the aggregate affect of the various aspects of the home on the price. However, I would need to do more analysis in regards to the assumptions of linearity, independence, homoscedasticity, and normality. At this point in the analysis, the KNN model has the best interpretability as one can just say we used the following variables and chose the houses that most resembled the homeowner's house in those aspects. In short, use the stepwise model if the only goal is to lower RMSE. Look more into the hand selected model if the goal is to know the affect of each parameter of the house price. Use KNN if the model needs to be interpretable and is needed immediately to evaluate home prices. 

<br/>

Lastly, I do recommend collecting additional data as this will allow for better models and lower RMSEs. In particular, I noticed that there is no neighborhood/zip-code data. For example, downtown properties are usually worth more than other areas. Or there may be particularly affluent zip-codes etc. It is my intuition that this kind of data would significantly improve the KNN model as well as improve the linear models. Furthermore, how many stories a house has, whether the property has a garage, and whether the property is in a school district could be particularly helpful.

<br/>

## 2. Classification and Retrospective Sampling

<br/>

### a. Make a bar plot of default probability by credit history

We can see in the bar plot below that in this dataset, people with good credit history has the highest probability of default and people with terrible credit history had the lowest probability of default. This is likely due to the way the bank chose to sample the data. 

<br/>

```{r chunk13}

#Create column with credit history
credit_history <- c("terrible", "poor", "good")

#Create column with default probabilities
default_probability <- c(
  german_credit %>% filter(history=="terrible") %>% summarise(probability = mean(Default)) %>% pull(probability),
  german_credit %>% filter(history=="poor") %>% summarise(probability = mean(Default)) %>% pull(probability),
  german_credit %>% filter(history=="good") %>% summarise(probability = mean(Default)) %>% pull(probability)
)

#Combine columns into one dataframe
df_default <- data.frame(credit_history, default_probability)

#Barplot the data
ggplot(data = df_default, aes(x = credit_history, y = default_probability)) + geom_bar(stat = "identity") +
  scale_y_continuous(limits = c(0,1)) + 
  xlab("Credit History") + 
  ylab("Default Probability") + 
  ggtitle("Default Probability Based on Credit History")

```

<br/>


### b. Build a logistics regression model for predicting default probability

Using the variables specified on the homework assignment, I created a logistic regression model. The logistics regression model returns coefficients in log odds. I have converted the coefficients back to odds in the output below. As can be seen from the output below, those with poor history and terrible history in this model actually reduce the probability that a given person would default. 

<br/>


```{r chunk14}

credit_split = initial_split(german_credit, prop = 0.8)
credit_train = training(credit_split)
credit_test = testing(credit_split)

glm_default <- glm(Default ~ duration + amount + installment + age + history + purpose + foreign, 
                   data = credit_train, family = 'binomial')

exp(coef(glm_default)) %>% round(3)
```

Now taking a look at the confusion matrix (setting the threshhold at 0.5), we can see that the model does not perform very well using this data. Below shows the results of a confusion matrix on the out of sample predictions. Especially concerning is the fact that out of the 56 people who actually defaulted on their loan, this model predicted that 46 of those would not default. 

```{r chunk15}
phat_test_default <- predict(glm_default, credit_test, type = 'response')
yhat_test_default <- ifelse(phat_test_default > 0.50, 1, 0) 
confusion_in = table(y = credit_test$Default, yhat = yhat_test_default)
confusion_in
```

```{r chunk16}

#accuracy of the confusion matric displayed above
accuracy_1 <- sum(diag(confusion_in))/sum(confusion_in)

#Use 5 folds to conduct cross validation
train_control <- trainControl(method = "cv", number = 5)
model <- train(factor(Default) ~ duration + amount + installment + age + history + purpose + foreign, 
                   data = german_credit, method = "glm", family = "binomial", trControl = train_control)
#average accuracy of the 5 folds
accuracy_2 <- model$results$Accuracy

cat("Using just one train-test split, the out of sample accuracy is:", accuracy_1,  "\n")
cat("Using 5 folds, the average out of sample accuracy is", accuracy_2)

```


<br/>

We can see from the 'history' variable in this logistic regression model that having a poor credit history reduces the odds of defaulting by a factor of more than 3, and having a terrible credit score reduces the odds of default by a factor of more than 6. This is because bank substantially oversampled the population of people who defaulted on the loan. Consequently, this dataset would not be appropriate in building a predictive model because the dataset is not representative of the population of people who borrow from this bank. This data may be helpful during exploratory data analysis to see what factors may possible contribute to defaults on loans. 

<br/>

Since the bank collects data on all of its customers, I would recommend that the bank use the population or a randomly selected subset of the population to design a predictive model. 



